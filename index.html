<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CooT: Learning to Coordinate In-Context with Coordination Transformers. An in-context coordination framework that adapts to unseen partners.">
  <meta name="keywords" content="CooT, MARL, Coordination, Transformers, Overcooked, HRI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CooT: Learning to Coordinate In-Context with Coordination Transformers</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CooT: Learning to Coordinate In-Context with Coordination Transformers</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">Anonymous Authors</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Under review as a conference paper at ICML 2026</span>
          </div>
          
          <div class="column has-text-centered">
            <div class="publication-links">
               <!-- Video Link. -->
              <span class="link-block">
                <a href="#video-section"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="fab fa-youtube"></i> -->
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!--Paper Link. -->
              <span class="link-block">
                <!-- <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark"> -->
                  <span class="icon">
                      <!-- <i class="ai ai-arxiv"></i> -->
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Coordination Demos</h2>
    <div class="columns is-multiline">
      
      <div class="column is-half">
        <div class="content">
          <h3 class="title is-5 has-text-centered">CooT (Ours)</h3>
          <video id="coot-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/COOT_1ep.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 has-text-centered">Our method: Rapid in-context adaptation.</p>
        </div>
      </div>

      <div class="column is-half">
        <div class="content">
          <h3 class="title is-5 has-text-centered">Behavioral Cloning (BC)</h3>
          <video id="bc-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/BC_1ep.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 has-text-centered">Standard BC: Struggles with unseen partner variations.</p>
        </div>
      </div>

      <div class="column is-half">
        <div class="content">
          <h3 class="title is-5 has-text-centered">HSP</h3>
          <video id="hsp-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/HSP_1ep.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 has-text-centered">Hidden Strategy Predictor baseline.</p>
        </div>
      </div>

      <div class="column is-half">
        <div class="content">
          <h3 class="title is-5 has-text-centered">MEP</h3>
          <video id="mep-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/MEP_1ep.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 has-text-centered">Maximum Entropy Population baseline.</p>
        </div>
      </div>

    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Effective coordination among artificial agents in dynamic and uncertain environments remains a significant challenge in multi-agent systems. 
            Existing approaches, such as self-play and population-based methods, either generalize poorly to unseen partners or require impractically extensive fine-tuning.
          </p>
          <p>
            To overcome these limitations, we propose <strong>Coordination Transformers (CooT)</strong>, a novel in-context coordination framework that uses recent interaction histories to rapidly adapt to unseen partners. 
            Unlike prior approaches that primarily aim to diversify training partners, CooT explicitly focuses on adapting to new partner behaviors by predicting actions aligned with observed interactions.
          </p>
          <p>
            Trained on trajectories collected from diverse pairs of agents with complementary preferences, CooT quickly learns effective coordination strategies without explicit supervision or parameter updates. 
            Across diverse coordination tasks in <strong>Overcooked</strong>, CooT consistently outperforms baselines including population-based approaches, gradient-based fine-tuning, and a Meta-RL-inspired contextual adaptation method. 
            Notably, fine-tuning proves unstable and ineffective, while Meta-RL struggles to achieve reliable coordination. 
            By contrast, CooT achieves stable, rapid in-context adaptation and is consistently ranked the most effective collaborator in human evaluations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
          <p>
            We propose <strong>Coordination Transformers (CooT)</strong>, a framework designed specifically for in-context partner adaptation. 
            CooT is trained on trajectories collected from interactions between pairs of agents whose behaviors reflect distinct underlying preferences (Hidden-Utility Markov Game).
          </p>
          <img src="./static/images/coot_fig_new.jpg" alt="CooT Architecture" style="width:100%; margin-top:20px; margin-bottom:20px;">
          <p>
            At test time, CooT coordinates with unseen partners by continually updating its context from recent episodes, which adapts to the partner online without gradient updates, enabling few-shot generalization.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


  <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results & Human Study</h2>
        <div class="content has-text-justified">
          <p>
            We evaluated CooT across diverse Overcooked layouts. CooT consistently outperforms baselines including population-based approaches (MEP, HSP) and gradient-based fine-tuning methods.
          </p>
        </div>
        
        <div class="columns is-centered">
            <div class="column is-half has-text-centered">
                 <img src="./static/images/main_table.png" alt="Quantitative Results" style="width:100%;">
                 <p>Table 1: Benchmark results across layouts.</p>
            </div>
            <div class="column is-half has-text-centered">
                 <img src="./static/images/human_study.png" alt="Human Study Results" style="width:100%;">
                 <p>Figure 2: Human study rankings.</p>
            </div>
        </div>

        <div class="content has-text-justified">
          <p>
            In our human-agent collaboration study, CooT was consistently ranked as the most effective collaborator by human participants, demonstrating its ability to handle the variability of real human behaviors.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
